\documentclass[12pt]{uebung}


\dozent{Przemysław Uznański}
\vorlesung{Algorithms for Big Data}
\semester{Fall Semester 2019}
%\tutoren{Tutoren name}
 
\usepackage{amsmath}
\usepackage{mathtools}
 
 
%\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb,wasysym}
%\usepackage{tikz}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

 
%\usepackage{multirow}

\usepackage[english]{babel}

 \begin{document}

 \startnummer{1}
 
\kopf[0]{07/01/2020}{11}

\newcommand{\bigo}{\mathcal{O}}
\renewcommand{\aufgname}{Exercise}

\begin{aufg}
Write explicitly the LP for compressed sensing $L_1$ norm minimization.
\end{aufg}

\begin{aufg}[2 pts.]
What is the complexity of the decision version of the $L_0$ norm minimization for the compressed sensing: given $A$, $b$ and $k$, is there $k$-sparse $x$ such that $Ax = b$.
\end{aufg}
\end{document}
